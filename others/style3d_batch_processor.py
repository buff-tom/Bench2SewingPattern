#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Style3D Benchmark æ•°æ®é›†æ„å»ºå·¥å…· (Batch Processor)

åŠŸèƒ½ï¼š
1. é€’å½’éå†è¾“å…¥ç›®å½•å¯»æ‰¾ project.jsonã€‚
2. è§£æå¤šå°ºç  (Grading) æ•°æ®ã€‚
3. æ‰§è¡Œæ ‡å‡†åŒ–ï¼šå¸ƒçº¹çº¿å¯¹é½ Y è½´ + é‡å¿ƒå½’é›¶ã€‚
4. ç”Ÿæˆ Ground Truth:
   - Spec JSON: åŒ…å«æ‹“æ‰‘å›¾å’Œå‡ ä½•æ•°æ®ã€‚
   - SVG: å¯è§†åŒ–çŸ¢é‡å›¾ï¼ˆè‡ªåŠ¨æ’ç‰ˆï¼‰ã€‚

é¢å¤–çº¦å®šï¼š
- è¾“å‡º spec / svg ç›´æ¥å­˜åˆ°ã€Œå›¾ç‰‡æ ¹ç›®å½•/style_dir/size_dirã€ä¸‹ï¼Œ
  ä¸å¯¹åº”çš„ front/back PNG æ”¾åœ¨åŒä¸€ä¸ªæ–‡ä»¶å¤¹ä¸­ã€‚
- æ–‡ä»¶å‘½åæ ¼å¼ï¼š{gender}_{region}_{styleID}_{size}_spec.jsonï¼Œspec å’Œ svg æ–‡ä»¶æ”¾å…¥ç›¸åº”çš„ `size_dir`ã€‚
"""

import os
import json
import math
import argparse
import traceback
import csv
import re
from typing import Dict, Any, List, Tuple
import logging

# ========= ä¾èµ–æ£€æŸ¥ä¸å¯¼å…¥ =========
try:
    from json2sewing import build_sewing_topology
    from size_to_svg_sym import (
        build_grade_maps,
        pattern_to_loops_grade,
        expand_with_symmetry,
        render_cut_and_seamline,  # å¼•ç”¨å¯è§†åŒ–æ¸²æŸ“
        pack_grid                # å¼•ç”¨æ’ç‰ˆç®—æ³•
    )
except ImportError as e:
    print("âŒ é”™è¯¯: ç¼ºå°‘ä¾èµ–æ–‡ä»¶ã€‚è¯·ç¡®ä¿ json2sewing.py å’Œ size_to_svg_sym.py åœ¨å½“å‰ç›®å½•ã€‚")
    exit(1)

# ========= å‡ ä½•æ ‡å‡†åŒ–å·¥å…· =========

def _calc_centroid(loops: List[List[Tuple[float, float]]]) -> Tuple[float, float]:
    """è®¡ç®—å¤šè½®å»“çš„å‡ ä½•ä¸­å¿ƒ"""
    sum_x, sum_y, count = 0.0, 0.0, 0
    for L in loops:
        for x, y in L:
            sum_x += x
            sum_y += y
            count += 1
    if count == 0:
        return (0.0, 0.0)
    return (sum_x / count, sum_y / count)

def _rotate_point(x: float, y: float, angle_rad: float) -> Tuple[float, float]:
    """2D æ—‹è½¬å˜æ¢"""
    cos_a = math.cos(angle_rad)
    sin_a = math.sin(angle_rad)
    return (x * cos_a - y * sin_a, x * sin_a + y * cos_a)

def _normalize_geometry(
    loops: List[List[Tuple[float, float]]], 
    piece_rotation_degrees: float
) -> Tuple[List[List[Tuple[float, float]]], Dict[str, Any]]:
    """
    æ ‡å‡†åŒ–æ ¸å¿ƒé€»è¾‘ï¼š
    1. æ—‹è½¬ï¼šæŠµæ¶ˆè£ç‰‡åŸå§‹æ—‹è½¬ï¼Œä½¿å¸ƒçº¹çº¿å‚ç›´ã€‚
    2. å¹³ç§»ï¼šå°†å‡ ä½•é‡å¿ƒç§»åŠ¨åˆ°åŸç‚¹ã€‚
    """
    # é€†å‘æ—‹è½¬ä»¥å¯¹é½å¸ƒçº¹çº¿åˆ° Y è½´
    angle_rad = -math.radians(piece_rotation_degrees)
    
    # 1. æ‰§è¡Œæ—‹è½¬
    rotated_loops = []
    for L in loops:
        new_L = [_rotate_point(x, y, angle_rad) for x, y in L]
        rotated_loops.append(new_L)
        
    # 2. è®¡ç®—æ–°é‡å¿ƒ
    cx, cy = _calc_centroid(rotated_loops)
    
    # 3. æ‰§è¡Œå¹³ç§»å½’é›¶
    final_loops = []
    for L in rotated_loops:
        final_loops.append([(x - cx, y - cy) for x, y in L])
        
    transform_info = {
        "grainline_correction_deg": float(piece_rotation_degrees),
        "translation_offset": (cx, cy)
    }
    
    return final_loops, transform_info

# ========= æ•°æ®åŠ è½½è¾…åŠ© =========

def load_json(path: str) -> Dict[str, Any]:
    try:
        return json.load(open(path, "r", encoding="utf-8"))
    except UnicodeDecodeError:
        return json.load(open(path, "r", encoding="latin-1"))

def build_indexes(root: Dict[str, Any]):
    """æ„å»º Class å’Œ ID çš„å¿«é€Ÿç´¢å¼•"""
    all_classes: Dict[int, List[Dict[str, Any]]] = {}
    by_id: Dict[int, Dict[str, Any]] = {}
    for arr in root.get("_objectsArrays", []):
        if isinstance(arr, list):
            for obj in arr:
                if isinstance(obj, dict):
                    cid = obj.get("_class")
                    oid = obj.get("_id")
                    if cid is not None: all_classes.setdefault(int(cid), []).append(obj)
                    if oid is not None: by_id[int(oid)] = obj
    return all_classes, by_id

def find_grade_group(all_classes: Dict[int, List[Dict[str, Any]]]) -> Dict[str, Any] | None:
    groups = all_classes.get(4153459189, []) # Style3D GradeGroup Class ID
    return groups[0] if groups else None

def piece_ids_from_gradegroup(grade_group: Dict[str, Any], fallback_ids: List[int]) -> List[int]:
    """è·å–å½“å‰æ¬¾å¼åŒ…å«çš„æ‰€æœ‰è£ç‰‡ID"""
    ids = [int(p[0]) for p in (grade_group.get("clothPieceFabricBaseMatrix") or [])]
    return ids if ids else [int(x) for x in (fallback_ids or [])]

# ========= Spec æ„å»ºé€»è¾‘ =========

def build_pieces_and_edge_lookup(
    by_id: Dict[int, Dict[str, Any]],
    grade_obj: Dict[str, Any],
    piece_ids_this: List[int],
) -> Tuple[List[Dict[str, Any]], Dict[int, Dict[str, Any]]]:
    
    # è·å–å½“å‰å°ºç çš„å‡ ä½•å¢é‡
    vmap, cmap, all_delta = build_grade_maps(by_id, grade_obj)

    pieces_json = []
    edge_lookup = {}

    for pid in piece_ids_this:
        piece = by_id.get(int(pid)) or {}
        patt_id = piece.get("pattern")
        if not patt_id: continue
        patt = by_id.get(int(patt_id)) or {}

        # 1. æå–åŸå§‹å‡ ä½• (Raw Geometry)
        raw_loops, _, seq_edge = pattern_to_loops_grade(patt, by_id, vmap, cmap, all_delta)
        if not raw_loops: continue 
        if len(raw_loops) > 1:
            raw_loops = raw_loops[:-1]
        # 2. æ ‡å‡†åŒ– (Normalization)
        rot_deg = float(piece.get("rotation", 0.0) or 0.0)
        norm_loops, transform_meta = _normalize_geometry(raw_loops, rot_deg)

        # 3. å»ºç«‹æ‹“æ‰‘ç´¢å¼• (Edge Indexing)
        local_index = 0
        edges_meta = []
        for sid in (patt.get("sequentialEdges") or []):
            sid_int = int(sid)
            eids = seq_edge.get(sid_int) or []
            for eid in eids:
                eid_int = int(eid)
                edge_info = {
                    "piece_id": int(pid),
                    "local_index": local_index, # è£ç‰‡å†…çš„ç¬¬å‡ æ¡è¾¹
                    "seqedge_id": sid_int,
                }
                edge_lookup[eid_int] = edge_info
                edges_meta.append({"edge_id": eid_int, **edge_info})
                local_index += 1
        
        # 4. ç»„è£… Piece æ•°æ®
        pieces_json.append({
            "id": int(pid),
            "name": piece.get("_name", str(pid)),
            "loops": [
                {
                    "loop_id": i,
                    "type": "outer" if i == 0 else "inner",
                    "vertices": L # å·²ç»æ˜¯å»ä½ç½®åŒ–ã€å¸ƒçº¹çº¿å¯¹é½çš„åæ ‡
                } for i, L in enumerate(norm_loops)
            ],
            "edges": edges_meta,
            "normalization": transform_meta
        })

    return pieces_json, edge_lookup

def build_seams(
    sewing_pairs: Dict[int, Tuple[Tuple[int, int], Tuple[int, int]]],
    edge_lookup: Dict[int, Dict[str, Any]]
) -> List[Dict[str, Any]]:
    """å°† json2sewing æå–çš„åŸå§‹å¯¹ï¼Œè½¬æ¢ä¸ºåŸºäº piece_id + local_index çš„å›¾ç»“æ„"""
    seams = []
    for cp_id, pair in sewing_pairs.items():
        (eA_beg, eA_end), (eB_beg, eB_end) = pair
        infoA = edge_lookup.get(int(eA_beg))
        infoB = edge_lookup.get(int(eB_beg))
        
        if infoA and infoB:
            seams.append({
                "id": int(cp_id),
                "source": {"piece": infoA["piece_id"], "edge": infoA["local_index"]},
                "target": {"piece": infoB["piece_id"], "edge": infoB["local_index"]}
            })
    return seams

def generate_visual_ground_truth(spec: Dict[str, Any], out_path_base: str):
    """
    æ ¹æ®ç”Ÿæˆçš„ Spec JSON ç»˜åˆ¶ SVGã€‚
    é‡è¦ï¼šJSON æ•°æ®æ˜¯å½’é›¶é‡å çš„ï¼Œè¿™é‡Œè°ƒç”¨ size_to_svg_sym çš„ pack_grid è¿›è¡Œæ’ç‰ˆï¼Œ
    ç”Ÿæˆé€‚åˆè§†è§‰æ¨¡å‹è®­ç»ƒçš„å¹³é“ºå›¾ (Pattern Layout)ã€‚
    """
    cut_loops = {}
    for p in spec["pieces"]:
        # æå–åæ ‡ç¯
        loops = [loop["vertices"] for loop in p["loops"]]
        cut_loops[p["id"]] = loops
    
    # ä½¿ç”¨ size_to_svg_sym çš„æ¸²æŸ“èƒ½åŠ›
    # è¿™ä¼šç”Ÿæˆ _cut.svg (çº¯è£ç‰‡) å’Œ _seam.svg (ç¼çº¿)
    render_cut_and_seamline(cut_loops, {}, out_path_base)

# ========= ä¸å›¾ç‰‡æ•°æ®é›†çš„æ˜ å°„ =========

def load_style_id_map(csv_path: str) -> Dict[str, str]:
    """
    è¯»å– style_id_map.csvï¼Œè¿”å›:
        {style_name: '00001', ...}
    """
    mapping: Dict[str, str] = {}
    if not os.path.exists(csv_path):
        print(f"âš ï¸ æ‰¾ä¸åˆ° style_id_map.csv: {csv_path}ï¼Œå°†ä¸ä½¿ç”¨ style_idã€‚")
        return mapping

    with open(csv_path, "r", encoding="utf-8") as f:
        reader = csv.DictReader(f)
        for row in reader:
            sid = str(row["style_id"]).strip()
            sname = row["style_name"].strip()
            if not sname:
                continue
            if sid.isdigit():
                sid_str = f"{int(sid):05d}"
            else:
                sid_str = sid
            mapping[sname] = sid_str
    print(f"âœ… å·²åŠ è½½ style_id_mapï¼Œå…± {len(mapping)} æ¡")
    return mapping


def find_style_dir(image_root: str, project_root: str) -> Tuple[str, str]:
    """
    åœ¨å›¾ç‰‡æ ¹ç›®å½•ä¸‹æ‰¾åˆ°å¯¹åº”æ¬¾å¼ç›®å½•åï¼Œå¹¶è¿”å›:
        (style_dir_name, style_id_str)
    è§„åˆ™ï¼š
      
      2) å¦åˆ™å°è¯•ç›´æ¥ç”¨ style_name åŒ¹é…ç›®å½•
      3) æœ€ç»ˆæ‰¾ä¸åˆ°åˆ™è¿”å› (style_name, '00000')
    """
    base_dir = os.path.basename(project_root)
    image_dir_list = os.path.abspath(image_root)
    if os.path.isdir(os.path.join(image_dir_list, base_dir)):
        
        return base_dir
    
    


def infer_prefix_from_images(size_dir: str) -> Tuple[str, str, str, str] | None:
    """
    å°è¯•ä» size ç›®å½•ä¸­çš„ä»»æ„ä¸€å¼ å›¾ç‰‡æ–‡ä»¶æ¨æ–­ï¼š
      gender, region, style_id_str, size_code
    é€šè¿‡è§£ææ–‡ä»¶å:
      gender_region_styleID_size_view.png
    """
    if not os.path.isdir(size_dir):
        return None
    for fname in os.listdir(size_dir):
        lower = fname.lower()
        if not (lower.endswith(".png") or lower.endswith(".jpg") or lower.endswith(".jpeg")):
            continue
        base = os.path.splitext(fname)[0]
        parts = base.split("_")
        if len(parts) < 4:
            continue
        gender, region, sid, size = parts[:4]
        return gender, region, sid, size
    return None

# ========= æµç¨‹æ§åˆ¶ =========

def process_single_project(
    project_root: str,
    project_path: str,
    image_root: str,
    default_gender: str,
    default_region: str,
):
    try:
        data = load_json(project_path)
        all_classes, by_id = build_indexes(data)
        
        garment = (all_classes.get(4038497362) or [{}])[0]
        grade_group = find_grade_group(all_classes)
        if not grade_group:
            return

        # Style3D å†…éƒ¨çš„æ¬¾å¼å
        style_name = (data.get("_fileName", "proj").split("~")[0] or "proj").strip()
        if "." in style_name:
            style_name = "_".join(style_name.split("."))

        print(f"\n====== å¤„ç†æ¬¾å¼: {style_name}  ======")

        # åœ¨å›¾ç‰‡ç›®å½•ä¸­æ‰¾åˆ°å¯¹åº”çš„æ¬¾å¼ç›®å½• + style_id
        style_dir_name = find_style_dir(image_root, project_root)
        # print(f"å¯¹åº”å›¾ç‰‡æ¬¾å¼ç›®å½•: {style_dir_name}")
        # print(type(style_dir_name))
        # exit(1)
        style_dir_full = os.path.join(image_root, style_dir_name)
        if not os.path.isdir(style_dir_full):
            print(f"âš ï¸ æ¬¾å¼ç›®å½•ä¸å­˜åœ¨ï¼š{style_dir_full}ï¼Œè·³è¿‡è¯¥æ¬¾å¼ã€‚")
            return

        # ç¡®å®šéœ€è¦å¤„ç†çš„ Grade IDs
        grade_ids = list(grade_group.get("grades") or [])
        
        # ç¡®å®šåŸºç¡€ Piece IDs
        fallback_ids = garment.get("clothPieces", [])

        for gid in grade_ids:
            grade_obj = by_id.get(int(gid))
            if not grade_obj:
                continue
            
            size_pattern = re.compile(r"(XXS|XS|S|M|L|XL|XXL|XXXL)")
            size_name = grade_obj.get("_name", f"G{gid}")
            match = size_pattern.search(size_name)
            if match:
                size_name = match.group(1)  # æå–å°ºå¯¸éƒ¨åˆ†
            else:   
                size_name = size_name  # ä¿æŒåŸæ ·
            size_dir_name = size_name
            size_dir_full = os.path.join(style_dir_full, size_dir_name)

            if not os.path.isdir(size_dir_full):
                print(f"âš ï¸ Size ç›®å½•ä¸å­˜åœ¨ï¼š{size_dir_full}ï¼Œå°†è‡ªåŠ¨åˆ›å»ºã€‚")
                logging.info(f"åˆ›å»º Size ç›®å½•ï¼š{size_dir_full}")
                os.makedirs(size_dir_full, exist_ok=True)

            # ä»å›¾ç‰‡æ–‡ä»¶ä¸­æ¨æ–­å‘½åå‰ç¼€ {gender}_{region}_{styleID}_{size}
            prefix_info = infer_prefix_from_images(size_dir_full)
            if prefix_info is not None:
                gender_code, region_code, sid_from_img, size_code = prefix_info
            else:
                gender_code = default_gender
                region_code = default_region
                sid_from_img = style_dir_name
                size_code = size_name.upper()

            base_prefix = f"{gender_code}_{region_code}_{sid_from_img}_{size_code}"
            print(f"  -> å°ºç : {size_name} | è¾“å‡ºå‰ç¼€: {base_prefix}")

            # 1. ç¡®å®šå½“å‰å°ºç çš„è£ç‰‡ (å«å¯¹ç§°å±•å¼€)
            pids = fallback_ids

            # 2. æ„å»ºæ ¸å¿ƒ Spec æ•°æ®
            pieces, edge_map = build_pieces_and_edge_lookup(by_id, grade_obj, pids)
            
            # 3. æ„å»ºæ‹“æ‰‘æ•°æ®
            raw_sewing = build_sewing_topology(garment, by_id, {}, pids)
            seams = build_seams(raw_sewing, edge_map)

            spec = {
                "meta": {
                    "style": style_name,
                    "style_dir": style_dir_name,
                    "style_id": sid_from_img,
                    "grade": size_name,
                    "size_code": size_code,
                    "unit": "mm",
                    "coordinate_system": "normalized_centered" # æ˜¾å¼æ ‡è®°åæ ‡ç³»
                },
                "pieces": pieces,
                "seams": seams
            }

            # 4. ä¿å­˜ Spec JSONï¼šæ”¾åœ¨å›¾ç‰‡çš„ size ç›®å½•ä¸‹
            json_path = os.path.join(size_dir_full, f"{base_prefix}_spec.json")
            with open(json_path, "w", encoding="utf-8") as f:
                json.dump(spec, f, ensure_ascii=False, indent=2)

            # 5. ä¿å­˜ SVGï¼šåŒç›®å½•ï¼ŒåŒå‰ç¼€
            svg_base = os.path.join(size_dir_full, base_prefix)
            generate_visual_ground_truth(spec, svg_base)
            
            print(f"     âœ… Spec å†™å…¥: {json_path}")
            print(f"     âœ… SVG å‰ç¼€: {svg_base}_*.svg")

    except Exception as e:
        print(f"âŒ å¤„ç†å¤±è´¥ {project_path}: {str(e)}")
        traceback.print_exc()


def process_root(
    input_dir: str,
    image_root: str,
    default_gender: str,
    default_region: str,
):
    count = 0
    print(f"ğŸš€ å¼€å§‹æ‰«æ PRJ ç›®å½•: {input_dir}")
    for root, _, files in os.walk(input_dir):
        if "project.json" in files:
            full_path = os.path.join(root, "project.json")
            process_single_project(
                root,
                full_path,
                image_root=image_root,
                default_gender=default_gender,
                default_region=default_region,
            )
            count += 1
            
    print(f"\nâœ… æ‰¹å¤„ç†ç»“æŸã€‚å…±å¤„ç† {count} ä¸ªé¡¹ç›®ã€‚")

# ========= å…¥å£ =========

if __name__ == "__main__":
    ap = argparse.ArgumentParser(description="Style3D Dataset Generator (ç»‘å®šå›¾ç‰‡ç›®å½•)")
    ap.add_argument("input_root", help="Raw Style3D data root directory (åŒ…å«è‹¥å¹² project.json)")
    ap.add_argument(
        "-i", "--image-root",
        required=True,
        help="å›¾ç‰‡æ•°æ®é›†æ ¹ç›®å½•ï¼ˆåŒ…å« style ç›®å½• / size ç›®å½• / PNG å›¾ç‰‡ï¼‰"
    )
    ap.add_argument(
        "--gender",
        default="m",
        help="é»˜è®¤ gender ç¼–ç ï¼Œä¾‹å¦‚ m / fï¼ˆå½“ä»å›¾ç‰‡ä¸­æ— æ³•æ¨æ–­æ—¶ä½¿ç”¨ï¼‰"
    )
    ap.add_argument(
        "--region",
        default="asia",
        help="é»˜è®¤ region ç¼–ç ï¼Œä¾‹å¦‚ asia / eurï¼ˆå½“ä»å›¾ç‰‡ä¸­æ— æ³•æ¨æ–­æ—¶ä½¿ç”¨ï¼‰"
    )
    args = ap.parse_args()

    input_root = os.path.abspath(args.input_root)
    image_root = os.path.abspath(args.image_root)

    if not os.path.exists(input_root):
        print("âŒ è¾“å…¥ PRJ ç›®å½•ä¸å­˜åœ¨")
        exit(1)
    if not os.path.exists(image_root):
        print("âŒ å›¾ç‰‡æ ¹ç›®å½•ä¸å­˜åœ¨")
        exit(1)

    process_root(
        input_dir=input_root,
        image_root=image_root,
        default_gender=args.gender,
        default_region=args.region,
    )
